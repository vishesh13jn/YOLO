{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import itertools\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "from data_parsing import voc_utils\n",
    "from data_parsing import voc_train\n",
    "\n",
    "class YOLO_TF:\n",
    "    \n",
    "    # Control variables\n",
    "    file_input = 'person.jpg'        #getting image from file\n",
    "    file_output_img = 'test/output.jpg' #target file\n",
    "    file_output_txt = 'test/output.txt'\n",
    "    weights_file = 'YOLO_small.ckpt'  #getting pretrained weights from file\n",
    "    fwrt_img = False     #writing image\n",
    "    written = None   \n",
    "    image = True         \n",
    "    imshow = True\n",
    "    display = True       \n",
    "    \n",
    "\n",
    "    # algorihtm variable\n",
    "    alpha = 0.1\n",
    "    threshold_value = 0.2\n",
    "    int_over_un_threshold_value = 0.5\n",
    "    num_class = 20                 #giving the number of classes\n",
    "    num_box = 2                    #specifying the number of boxes\n",
    "    grid_size = 7                  #specifying grid size\n",
    "    #using following classes for classification\n",
    "    classes = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "               \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "    w_img = 640                    #image width\n",
    "    h_img = 480                    #image heigth\n",
    "\n",
    "    # training variaible\n",
    "    training = False\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    lamb_cord = 5.0\n",
    "    lamb_nobj = 0.5\n",
    "    label = None\n",
    "    label = None\n",
    "    ind_in_epoch = 0\n",
    "    epochs_done = 0\n",
    "\n",
    "    def __init__(self):\n",
    "        self.network_building()\n",
    "        if self.training:          #if self.training == True, training will be done\n",
    "            self.build_training()\n",
    "            self.train()\n",
    "        print(\"detection\")\n",
    "        print(self.file_input)\n",
    "        if self.file_input is not None:\n",
    "            if self.image:\n",
    "                print(\"image\")\n",
    "                self.input_file(self.file_input)\n",
    "\n",
    "    def define_layer_convulation(self, idx, inputs, filters, size, stride, trainable=False):   #defining convulation layers\n",
    "        channels = inputs.get_shape()[3]      #getting number of channels\n",
    "        weight = tf.Variable(tf.truncated_normal([size, size, int(channels), filters], stddev=0.1), trainable=trainable)  #getting weigths\n",
    "        biases = tf.Variable(tf.constant(0.1, shape=[filters]), trainable=trainable)                                      #getting biases\n",
    "\n",
    "        pad_size = size // 2           #padding size\n",
    "        pad_mat = np.array([[0, 0], [pad_size, pad_size], [pad_size, pad_size], [0, 0]])\n",
    "        inputs_pad = tf.pad(inputs, pad_mat)\n",
    "\n",
    "        conv = tf.nn.conv2d(inputs_pad, weight, strides=[1, stride, stride, 1], padding='VALID',\n",
    "                            name=str(idx) + '_conv')\n",
    "        layer_convolutionbiased = tf.add(conv, biases, name=str(idx) + '_layer_convolutionbiased')\n",
    "        if self.display: print ('    Layer  %d : Type = Conv, Size = %d * %d, Stride = %d, Filters = %d, Input channels = %d' %\n",
    "        (idx, size, size, stride, filters, int(channels)))\n",
    "        return tf.maximum(tf.multiply(self.alpha, layer_convolutionbiased), layer_convolutionbiased, name=str(idx) + '_leaky_relu')\n",
    "\n",
    "    def define_layer_pooling(self, idx, inputs, size, stride):                        #defining pooling layers\n",
    "        if self.display: print ('    Layer  %d : Type = Pool, Size = %d * %d, Stride = %d' % (\n",
    "        idx, size, size, stride))\n",
    "        return tf.nn.max_pool(inputs, ksize=[1, size, size, 1], strides=[1, stride, stride, 1], padding='SAME',\n",
    "                              name=str(idx) + '_pool')\n",
    "\n",
    "    def define_fullyconnected_layer(self, idx, inputs, hiddens, flat=False, linear=False, trainable=False):     #defining fully connected layers\n",
    "        input_shape = inputs.get_shape().as_list()\n",
    "        if flat:\n",
    "            dim = input_shape[1] * input_shape[2] * input_shape[3]\n",
    "            inputs_transposed = tf.transpose(inputs, (0, 3, 1, 2))\n",
    "            inputs_processed = tf.reshape(inputs_transposed, [-1, dim])\n",
    "        else:\n",
    "            dim = input_shape[1]\n",
    "            inputs_processed = inputs\n",
    "        #weight = tf.Variable(tf.truncated_normal([dim, hiddens], stddev=0.1), trainable=trainable)\n",
    "        weight = tf.Variable(tf.zeros([dim, hiddens]), trainable=trainable)\n",
    "        biases = tf.Variable(tf.constant(0.1, shape=[hiddens]), trainable=trainable)\n",
    "        if self.display: print ('    Layer  %d : Type = Full, Hidden = %d, Input dimension = %d, Flat = %d, Activation = %d' % (\n",
    "        idx, hiddens, int(dim), int(flat), 1 - int(linear)))\n",
    "        if linear: return tf.add(tf.matmul(inputs_processed, weight), biases, name=str(idx) + '_fc')\n",
    "        ip = tf.add(tf.matmul(inputs_processed, weight), biases)\n",
    "        return tf.maximum(tf.multiply(self.alpha, ip), ip, name=str(idx) + '_fc')\n",
    "\n",
    "    def dropout(self, idx, inputs):                    #defining dropout\n",
    "        if self.display: print ('    Layer  %d : Type = DropOut' % (idx))\n",
    "        return tf.nn.dropout(inputs, keep_prob=self.keep_prob)\n",
    "\n",
    "    def cvmat_input(self, img):     #getting input from cvmat\n",
    "        s = time.time()\n",
    "        self.h_img, self.w_img, _ = img.shape           #getting image height and width\n",
    "        img_resized = cv2.resize(img, (448, 448))            #resizing the image\n",
    "        img_RGB = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)      #for RGB image\n",
    "        img_resized_np = np.asarray(img_RGB)\n",
    "        inputs = np.zeros((1, 448, 448, 3), dtype='float32')      #in same dimension as that of modified image\n",
    "        inputs[0] = (img_resized_np / 255.0) * 2.0 - 1.0\n",
    "        in_dict = {self.x: inputs, self.keep_prob: 1.0}           #input dictionary\n",
    "        net_output = self.sess.run(self.layer_fullyconnected32, feed_dict=in_dict)       \n",
    "        self.result = self.interpret_output(net_output[0])\n",
    "        strtime = str(time.time() - s)\n",
    "        if self.display: print ('Elapsed time : ' + strtime + ' secs' + '\\n')\n",
    "\n",
    "    def input_file(self, filename):     #detecting from file\n",
    "        if self.display: print ('Detect from ' + filename)\n",
    "        img = cv2.imread(filename)\n",
    "        self.cvmat_input(img)\n",
    "        self.disp_results(img, self.result)\n",
    "       \n",
    "    def network_building(self):                  #building the network\n",
    "        if self.display: print (\"Building YOLO_small graph...\")\n",
    "        self.x = tf.placeholder('float32', [None, 448, 448, 3])\n",
    "        self.layer_convolution1 = self.define_layer_convulation(1, self.x, 64, 7, 2,trainable=self.training)  #1st convulation layer\n",
    "        self.layer_pooling2 = self.define_layer_pooling(2, self.layer_convolution1, 2, 2)          #2nd pooling layer\n",
    "        self.layer_convolution3 = self.define_layer_convulation(3, self.layer_pooling2, 192, 3, 1,trainable=self.training)        #3rd convulation layer\n",
    "        self.layer_pooling4 = self.define_layer_pooling(4, self.layer_convolution3, 2, 2)          #4th pooling layer\n",
    "        self.layer_convolution5 = self.define_layer_convulation(5, self.layer_pooling4, 128, 1, 1,trainable=self.training)        #5th convulation layer\n",
    "        self.layer_convolution6 = self.define_layer_convulation(6, self.layer_convolution5, 256, 3, 1,trainable=self.training)        #6th convulation layer\n",
    "        self.layer_convolution7 = self.define_layer_convulation(7, self.layer_convolution6, 256, 1, 1,trainable=self.training)        #7th convulation layer\n",
    "        self.layer_convolution8 = self.define_layer_convulation(8, self.layer_convolution7, 512, 3, 1,trainable=self.training)        #8th convulation layer\n",
    "        self.layer_pooling9 = self.define_layer_pooling(9, self.layer_convolution8, 2, 2)          #9th pooling layer\n",
    "        self.layer_convolution10 = self.define_layer_convulation(10, self.layer_pooling9, 256, 1, 1,trainable=self.training)      #10th convulation layer\n",
    "        self.layer_convolution11 = self.define_layer_convulation(11, self.layer_convolution10, 512, 3, 1,trainable=self.training)     #11th convulation layer\n",
    "        self.layer_convolution12 = self.define_layer_convulation(12, self.layer_convolution11, 256, 1, 1,trainable=self.training)     #12th convulation layer\n",
    "        self.layer_convolution13 = self.define_layer_convulation(13, self.layer_convolution12, 512, 3, 1,trainable=self.training)     #13th convulation layer\n",
    "        self.layer_convolution14 = self.define_layer_convulation(14, self.layer_convolution13, 256, 1, 1,trainable=self.training)     #14th convulation layer\n",
    "        self.layer_convolution15 = self.define_layer_convulation(15, self.layer_convolution14, 512, 3, 1,trainable=self.training)     #15th convulation layer\n",
    "        self.layer_convolution16 = self.define_layer_convulation(16, self.layer_convolution15, 256, 1, 1,trainable=self.training)     #16th convulation layer\n",
    "        self.layer_convolution17 = self.define_layer_convulation(17, self.layer_convolution16, 512, 3, 1,trainable=self.training)     #17th convulation layer\n",
    "        self.layer_convolution18 = self.define_layer_convulation(18, self.layer_convolution17, 512, 1, 1,trainable=self.training)     #18th convulation layer\n",
    "        self.layer_convolution19 = self.define_layer_convulation(19, self.layer_convolution18, 1024, 3, 1,trainable=self.training)    #19th convulation layer\n",
    "        self.layer_pooling20 = self.define_layer_pooling(20, self.layer_convolution19, 2, 2)       #20th pooling layer\n",
    "        self.layer_convolution21 = self.define_layer_convulation(21, self.layer_pooling20, 512, 1, 1,trainable=self.training)     #21st convulation layer\n",
    "        self.layer_convolution22 = self.define_layer_convulation(22, self.layer_convolution21, 1024, 3, 1,trainable=self.training)    #22nd convulation layer\n",
    "        self.layer_convolution23 = self.define_layer_convulation(23, self.layer_convolution22, 512, 1, 1,trainable=self.training)     #23rd convulation layer\n",
    "        self.layer_convolution24 = self.define_layer_convulation(24, self.layer_convolution23, 1024, 3, 1,trainable=self.training)    #24th convulation layer\n",
    "        self.layer_convolution25 = self.define_layer_convulation(25, self.layer_convolution24, 1024, 3, 1,trainable=self.training)    #25th convulation layer\n",
    "        self.layer_convolution26 = self.define_layer_convulation(26, self.layer_convolution25, 1024, 3, 2,trainable=self.training)    #26th convulation layer\n",
    "        self.layer_convolution27 = self.define_layer_convulation(27, self.layer_convolution26, 1024, 3, 1,trainable=self.training)    #27th convulation layer\n",
    "        self.layer_convolution28 = self.define_layer_convulation(28, self.layer_convolution27, 1024, 3, 1,trainable=self.training)    #28th convulation layer\n",
    "        self.layer_fullyconnected29 = self.define_fullyconnected_layer(29, self.layer_convolution28, 512, flat=True, linear=False,trainable=self.training)   #29th fully connected layer\n",
    "        self.layer_fullyconnected30 = self.define_fullyconnected_layer(30, self.layer_fullyconnected29, 4096, flat=False, linear=False,trainable=self.training)   #30th fully connected layer\n",
    "        self.drop_31 = self.dropout(31, self.layer_fullyconnected30)                                                          #31st dropout layer\n",
    "        self.layer_fullyconnected32 = self.define_fullyconnected_layer(32, self.drop_31, 1470, flat=False, linear=True,trainable=self.training)  #32nd fully connected layer\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.saver = tf.train.Saver()                           #saving the model\n",
    "        self.saver.restore(self.sess, self.weights_file)\n",
    "        if self.display: print (\"Loading complete!\" + '\\n')\n",
    "    \n",
    "    \n",
    "    def disp_results(self, img, results):      #for displaying results\n",
    "        cp_img = img.copy()                    #making copy of image\n",
    "        for i in range(len(results)):\n",
    "            x = int(results[i][1])\n",
    "            y = int(results[i][2])\n",
    "            w = int(results[i][3]) // 2\n",
    "            h = int(results[i][4]) // 2\n",
    "            if self.display: print ('    class : ' + results[i][0] + ' , [x,y,w,h]=[' + str(x) + ',' + str(\n",
    "                y) + ',' + str(int(results[i][3])) + ',' + str(int(results[i][4])) + '], Confidence = ' + str(\n",
    "                results[i][5]))\n",
    "            if self.fwrt_img or self.imshow:\n",
    "                cv2.rectangle(cp_img, (x - w, y - h), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.rectangle(cp_img, (x - w, y - h - 20), (x + w, y - h), (125, 125, 125), -1)\n",
    "                cv2.putText(cp_img, results[i][0] + ' : %.2f' % results[i][5], (x - w + 5, y - h - 7),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "            \n",
    "        if self.imshow:\n",
    "            cv2.imshow('YOLO_small detection', cp_img)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "    def interpret_output(self, output):                         #defining the function for interpreting output\n",
    "        probs = np.zeros((7, 7, 2, 20))                        \n",
    "        class_probability = np.reshape(output[0:980], (7, 7, 20))\n",
    "        scales = np.reshape(output[980:1078], (7, 7, 2))\n",
    "        bound_box = np.reshape(output[1078:], (7, 7, 2, 4))        \n",
    "        offset = np.transpose(np.reshape(np.array([np.arange(7)] * 14), (2, 7, 7)), (1, 2, 0))\n",
    "\n",
    "        bound_box[:, :, :, 0] += offset\n",
    "        bound_box[:, :, :, 1] += np.transpose(offset, (1, 0, 2))\n",
    "        bound_box[:, :, :, 0:2] = bound_box[:, :, :, 0:2] / 7.0\n",
    "        bound_box[:, :, :, 2] = np.multiply(bound_box[:, :, :, 2], bound_box[:, :, :, 2])\n",
    "        bound_box[:, :, :, 3] = np.multiply(bound_box[:, :, :, 3], bound_box[:, :, :, 3])\n",
    "\n",
    "        bound_box[:, :, :, 0] *= self.w_img\n",
    "        bound_box[:, :, :, 1] *= self.h_img\n",
    "        bound_box[:, :, :, 2] *= self.w_img\n",
    "        bound_box[:, :, :, 3] *= self.h_img\n",
    "\n",
    "        for i in range(2):\n",
    "            for j in range(20):\n",
    "                probs[:, :, i, j] = np.multiply(class_probability[:, :, j], scales[:, :, i])\n",
    "\n",
    "        filter_mat_probs = np.array(probs >= self.threshold_value, dtype='bool')\n",
    "        filter_mat_bound_box = np.nonzero(filter_mat_probs)\n",
    "        bound_box_filtered = bound_box[filter_mat_bound_box[0], filter_mat_bound_box[1], filter_mat_bound_box[2]]\n",
    "        probs_filtered = probs[filter_mat_probs]\n",
    "        classes_num_filtered = np.argmax(filter_mat_probs, axis=3)[\n",
    "            filter_mat_bound_box[0], filter_mat_bound_box[1], filter_mat_bound_box[2]]\n",
    "\n",
    "        argsort = np.array(np.argsort(probs_filtered))[::-1]\n",
    "        bound_box_filtered = bound_box_filtered[argsort]\n",
    "        probs_filtered = probs_filtered[argsort]\n",
    "        classes_num_filtered = classes_num_filtered[argsort]\n",
    "\n",
    "        for i in range(len(bound_box_filtered)):\n",
    "            if probs_filtered[i] == 0: continue\n",
    "            for j in range(i + 1, len(bound_box_filtered)):\n",
    "                if self.int_over_un(bound_box_filtered[i], bound_box_filtered[j]) > self.int_over_un_threshold_value:\n",
    "                    probs_filtered[j] = 0.0\n",
    "\n",
    "        filter_int_over_un = np.array(probs_filtered > 0.0, dtype='bool')\n",
    "        bound_box_filtered = bound_box_filtered[filter_int_over_un]\n",
    "        probs_filtered = probs_filtered[filter_int_over_un]\n",
    "        classes_num_filtered = classes_num_filtered[filter_int_over_un]\n",
    "\n",
    "        result = []\n",
    "        for i in range(len(bound_box_filtered)):\n",
    "            result.append([self.classes[classes_num_filtered[i]], bound_box_filtered[i][0], bound_box_filtered[i][1],\n",
    "                           bound_box_filtered[i][2], bound_box_filtered[i][3], probs_filtered[i]])\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def develop_training(self):\n",
    "        #developing training variables and loss function\n",
    "        \n",
    "        self.y_ = tf.placeholder(tf.float32, [None,7, 7, 2]) #y-coordinate of centre of box\n",
    "        self.h_ = tf.placeholder(tf.float32, [None,7, 7, 2]) #heigth of box\n",
    "        self.x_ = tf.placeholder(tf.float32, [None,7, 7, 2]) #x-coordinate of centre of box\n",
    "        self.C_ = tf.placeholder(tf.float32, [None,7, 7, 2]) #class of image predicted\n",
    "        self.w_ = tf.placeholder(tf.float32, [None,7, 7, 2]) #width of box\n",
    "        self.p_ = tf.placeholder(tf.float32, [None,7, 7, 20])#probability of predicted class\n",
    "        self.noobj = tf.placeholder(tf.float32, [None,7, 7, 2])\n",
    "        self.obj = tf.placeholder(tf.float32, [None,7, 7, 2])\n",
    "        self.Obj_I = tf.placeholder(tf.float32, [None,7, 7])\n",
    "        \n",
    "\n",
    "        #network of o/p defined\n",
    "        output = self.fc_32\n",
    "        img_nb = tf.shape(self.x_)[0]\n",
    "        class_probability = tf.reshape(output[0:img_nb,0:980], (img_nb,7, 7, 20))\n",
    "        scales = tf.reshape(output[0:img_nb,980:1078], (img_nb,7, 7, 2))\n",
    "        bound_box = tf.reshape(output[0:img_nb,1078:], (img_nb,7, 7, 2, 4))\n",
    "\n",
    "        bound_box0 = bound_box[:,:, :, :, 0]           \n",
    "        bound_box1 = bound_box[:,:, :, :, 1]\n",
    "        bound_box2 = bound_box[:,:, :, :, 2]\n",
    "        bound_box3 = bound_box[:,:, :, :, 3]\n",
    "\n",
    "        # loss funtion\n",
    "        self.subX = tf.sub(bound_box0, self.x_)    #loss for x-coordinate of centre of box\n",
    "        self.subY = tf.sub(bound_box1, self.y_)    #loss for y-coordinate of centre of box\n",
    "        self.subW = tf.sub(tf.sqrt(tf.abs(bound_box2)), tf.sqrt(self.w_))  #loss for width of box\n",
    "        self.subH = tf.sub(tf.sqrt(tf.abs(bound_box3)), tf.sqrt(self.h_))  #loss for heigth of box\n",
    "        self.subC = tf.sub(scales, self.C_)   #loss for class of image predicted\n",
    "        self.subP = tf.sub(class_probability, self.p_)  #loss for probability of predicted class\n",
    "        self.lossX=tf.multiply(self.lamb_cord,tf.reduce_sum(tf.multiply(self.obj,tf.multiply(self.subX, self.subX)),axis=[1,2,3]))\n",
    "        self.lossY=tf.multiply(self.lamb_cord, tf.reduce_sum(tf.multiply(self.obj, tf.multiply(self.subY, self.subY)),axis=[1,2,3]))\n",
    "        self.lossW=tf.multiply(self.lamb_cord, tf.reduce_sum(tf.multiply(self.obj, tf.multiply(self.subW, self.subW)),axis=[1,2,3]))\n",
    "        self.lossH=tf.multiply(self.lamb_cord, tf.reduce_sum(tf.multiply(self.obj, tf.multiply(self.subH, self.subH)),axis=[1,2,3]))\n",
    "        self.lossCObj=tf.reduce_sum(tf.multiply(self.obj, tf.multiply(self.subC, self.subC)),axis=[1,2,3])\n",
    "        self.lossCNobj=tf.multiply(self.lamb_nobj, tf.reduce_sum(tf.multiply(self.noobj, tf.multiply(self.subC, self.subC)),axis=[1,2,3]))\n",
    "        self.lossP=tf.reduce_sum(tf.multiply(self.Obj_I,tf.reduce_sum(tf.multiply(self.subP, self.subP), axis=3)) ,axis=[1,2])\n",
    "        self.loss = tf.add_n((self.lossX,self.lossY,self.lossW,self.lossH,self.lossCObj,self.lossCNobj,self.lossP))\n",
    "        self.loss = tf.reduce_mean(self.loss)     #merging all the losses which are calculated in steps\n",
    "\n",
    "        #variable for the training\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        starter_learning_rate = 0.001\n",
    "        decay = 0.0005\n",
    "        end_learning_rate = 0.01\n",
    "        self.epoch=tf.placeholder(tf.int32)\n",
    "\n",
    "        # Different case of learning rate\n",
    "        def learning_rate1():\n",
    "            return tf.train.polynomial_decay(starter_learning_rate, global_step, decay, end_learning_rate=end_learning_rate,\n",
    "                                             power=1.0)\n",
    "        def learning_rate2():\n",
    "            return tf.constant(0.01)\n",
    "        def learning_rate3():\n",
    "            return tf.constant(0.001)\n",
    "        def learning_rate4():\n",
    "            return tf.constant(0.0001)\n",
    "        lr = tf.case({tf.less_equal(self.epoch, 1): learning_rate1,\n",
    "                      tf.logical_and(tf.greater(self.epoch, 76), tf.less_equal(self.epoch, 106)): learning_rate2,\n",
    "                      tf.logical_and(tf.greater(self.epoch, 106), tf.less_equal(self.epoch, 136)): learning_rate3,\n",
    "                      tf.greater(self.epoch, 136): learning_rate4},learning_rate4, exclusive=True)\n",
    "\n",
    "        self.train_step = tf.train.MomentumOptimizer(learning_rate=lr, momentum=0.9).minimize(self.loss,global_step=global_step)\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    \n",
    "    def int_over_un(self, box1, box2):           #function for intersection over union\n",
    "        l_r = min(box1[1] + 0.5 * box1[3], box2[1] + 0.5 * box2[3]) - max(box1[1] - 0.5 * box1[3],\n",
    "                                                                         box2[1] - 0.5 * box2[3])\n",
    "        t_b = min(box1[0] + 0.5 * box1[2], box2[0] + 0.5 * box2[2]) - max(box1[0] - 0.5 * box1[2],\n",
    "                                                                         box2[0] - 0.5 * box2[2])\n",
    "        \n",
    "        if t_b < 0 or l_r < 0:\n",
    "            intersection = 0\n",
    "        else:\n",
    "            intersection= t_b * l_r\n",
    "            iou_value = intersection / (box1[2] * box1[3] + box2[2] * box2[3] - intersection)\n",
    "            print(\"IOU%=\",iou_value*100)\n",
    "        return intersection / (box1[2] * box1[3] + box2[2] * box2[3] - intersection)\n",
    "    \n",
    "    def build_label (self,img_filenms,epoch):     #function for building label\n",
    "            glob_X=[]; glob_Y=[]; glob_W=[]; glob_H=[]; glob_C=[]; glob_P=[]; glob_obj=[]; glob_objI=[];\n",
    "            glob_noobj=[];Image=[]\n",
    "            for img_filenm in img_filenms:\n",
    "                Lab_Pre=voc_train.get_training_data(img_filenm)\n",
    "                x = np.zeros([7,7,2]); y = np.zeros([7,7,2]); w = np.zeros([7,7,2]); h = np.zeros([7,7,2])\n",
    "                C = np.zeros([7,7,2]); p = np.zeros([7,7,20]); obj = np.zeros([7,7,2]); objI = np.zeros([7,7])\n",
    "                noobj = np.ones([7,7,2]); img = voc_utils.load_img(img_filenm)\n",
    "                for i,j in itertools.product(range(0,7),range(0,7)):\n",
    "                    if Lab_Pre[i][j] is not None:\n",
    "                        ind=0\n",
    "                        while(len(Lab_Pre[i][j])>ind and ind<2):\n",
    "                            x[i][j][ind]= (float(Lab_Pre[i][j][ind][0])/len(img))*7-i\n",
    "                            y[i][j][ind] = (float(Lab_Pre[i][ j][ ind][ 1])/len(img[0]))*7-j\n",
    "                            w[i][j][ind] = np.sqrt(Lab_Pre[i][ j][ ind][ 2])/len(img)*7\n",
    "                            h[i][j][ind] = np.sqrt(Lab_Pre[i][ j][ ind][ 3])/len(img[0])\n",
    "                            C[i][j][ind] = 1.0\n",
    "                            p[i][j][self.classes.ind(Lab_Pre[i][ j][ ind][ 4])] = 1.0/float(len(Lab_Pre[i][j]))\n",
    "                            obj[i][j][ind] = 1.0\n",
    "                            objI[i][j] = 1.0\n",
    "                            noobj[i][j][ ind]=0.0\n",
    "                            ind=ind+1\n",
    "                glob_X.append(x); glob_Y.append(y); glob_W.append(w); glob_H.append(h); glob_C.append(C)\n",
    "                glob_P.append(p); glob_obj.append(obj); glob_objI.append(objI); glob_noobj.append(noobj)\n",
    "\n",
    "                #resize the image\n",
    "                Resize_Img = cv2.resize(img, (448, 448))\n",
    "                img_RGB = cv2.cvtColor(Resize_Img, cv2.COLOR_BGR2RGB)\n",
    "                Resize_Img_np = np.asarray(img_RGB)\n",
    "                ips = np.zeros((1, 448, 448, 3), dtype='float32')\n",
    "                ips[0] = (Resize_Img_np / 255.0) * 2.0 - 1.0\n",
    "                Image.append(ips[0])\n",
    "            glob_X=np.array(glob_X); glob_Y=np.array(glob_Y); glob_W=np.array(glob_W)\n",
    "            glob_H=np.array(glob_H); glob_C=np.array(glob_C); glob_P=np.array(glob_P)\n",
    "            glob_obj=np.array(glob_obj); glob_objI=np.array(glob_objI); glob_noobj=np.array(glob_noobj)\n",
    "            Image=np.array(Image)\n",
    "            return {self.x:Image,self.x_:glob_X,self.y_:glob_Y,self.w_:glob_W,self.h_:glob_H,self.C_:glob_C,\n",
    "                    self.p_:glob_P,self.obj:glob_obj,self.Obj_I:glob_objI,self.noobj:glob_noobj,\n",
    "                    self.keep_prob: 0.5,self.epoch:epoch}\n",
    "\n",
    "    \n",
    "    def training_step(self, i, tst_upd, trn_upd):     #defining the training step\n",
    "        for nbatch in range(0,len(self.label)/64):\n",
    "            dict=self.build_label(self.next_batch(64,exam_num=len(self.label)),i)\n",
    "            self.sess.run(self.train_step, dict)\n",
    "\n",
    "        trn_lst = []                   #training list \n",
    "        tst_lst = []                   #test list\n",
    "\n",
    "        if trn_upd:                    #for updating taining list\n",
    "            l = self.sess.run(self.loss, feed_dict=self.build_label(self.label,i))\n",
    "            trn_lst.append(l)\n",
    "\n",
    "        if tst_upd:                    #for updating test list\n",
    "            l= self.sess.run(self.loss, feed_dict=self.build_label(self.label_test,i))\n",
    "            print(\"\\r\", i, \"loss : \", l)\n",
    "            tst_lst.append(l)\n",
    "\n",
    "        return (trn_lst, tst_lst)\n",
    "\n",
    "    def next_batch(self,sizeofbatch, exam_num):\n",
    "        start = self.epoc_ind\n",
    "        self.epoc_ind += sizeofbatch\n",
    "        if self.epoc_ind > exam_num:\n",
    "            # Finished epoch\n",
    "            self.epochs_done += 1\n",
    "            # Shuffle the data\n",
    "            perm = np.arange(exam_num)\n",
    "            np.random.shuffle(perm)\n",
    "            self.label=self.label[perm]\n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self.epoc_ind = sizeofbatch\n",
    "            assert sizeofbatch <= exam_num\n",
    "        end = self.epoc_ind\n",
    "        return  self.label[start:end]\n",
    "    \n",
    "    #Training   function: This function is the first step in the training procedure.\n",
    "    def train(self):\n",
    "        trn_lst = []\n",
    "        tst_lst = []\n",
    "        self.label=voc_utils.imgs_from_category_as_list(\"bird\", \"train\")    #training for a sample of bird images with training tag\n",
    "        self.label_test=voc_utils.imgs_from_category_as_list(\"bird\", \"val\") #testing for bird images with validating tag\n",
    "        iteration_train = 137      #This should ideally be 137\n",
    "        epoch_size = 5             \n",
    "        for i in range(iteration_train):\n",
    "            test = True             \n",
    "            if i % epoch_size == 0:\n",
    "                test = True\n",
    "            l, tl = self.training_step(i, test, test)\n",
    "            trn_lst += l\n",
    "            tst_lst += tl\n",
    "        print(\"train loss\")\n",
    "        print(trn_lst)\n",
    "        print(\"test loss\")\n",
    "        print(tst_lst)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    yolo = YOLO_TF()\n",
    "    cv2.waitKey(1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
